
# ğŸ“° TruthScope ğ–£¨ğŸ”

Ce projet vise Ã  dÃ©tecter automatiquement les **fake news** Ã  partir de textes en utilisant un modÃ¨le BERT optimisÃ©.  
Il s'agit d'une solution complÃ¨te comprenant un backend en Python (FastAPI) et une interface utilisateur simple (HTML/CSS/JS).

---

## ğŸ“Š Dataset utilisÃ©

Le modÃ¨le a Ã©tÃ© entraÃ®nÃ© sur un dataset construit Ã  partir de la **fusion de trois sources de donnÃ©es fiables** largement utilisÃ©es dans la recherche sur la dÃ©tection de fausses informations :

1. **FakeNewsNet** ([source](https://github.com/KaiDMML/FakeNewsNet))  
   - Contient deux sous-ensembles : *PolitiFact* et *GossipCop*  
   - Chaque instance est Ã©tiquetÃ©e comme `Fake` ou `True`

2. **TruthSeeker 2023**  
   - Dataset rÃ©cent dÃ©diÃ© Ã  la dÃ©tection des fake news sur les rÃ©seaux sociaux  
   - DonnÃ©es vÃ©rifiÃ©es manuellement, avec Ã©tiquetage binaire (`0`: fake, `1`: real)

3. **Fake vs Real News Dataset** ([source GitHub](https://github.com/HNDeshanSamarathunga/FakeNewsDetection))  
   - Contient des textes dâ€™actualitÃ©s simples classÃ©s en `fake` et `true`

ğŸ‘‰ Toutes les donnÃ©es ont Ã©tÃ© **nettoyÃ©es, uniformisÃ©es et concatÃ©nÃ©es** dans un seul dataset final utilisÃ© pour l'entraÃ®nement.  
Ce dataset fusionnÃ© contient deux colonnes principales :

- `text` : contenu textuel de la news  
- `label` : `0` pour les fake news, `1` pour les vraies

---

## ğŸš€ DÃ©marrer le projet

### 1. Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/AnisBenini/Detection_of_Fake_News.git 
cd Detection_of_Fake_News
```

### 2. Activer le backend (FastAPI)

Depuis le dossier `main`, lancez le serveur backend :

```bash
cd main
uvicorn app:app --reload
```

> âš ï¸ Assurez-vous que tous les packages nÃ©cessaires sont installÃ©s (`transformers`, `fastapi`, `uvicorn`, etc.)

### 3. Lancer lâ€™interface utilisateur

Depuis le dossier `UI`, ouvrez le fichier `index.html` avec **Live Server** (via Visual Studio Code ou tout outil similaire) :

```bash
cd ../UI
```

> Clic droit sur `index.html` â†’ **"Open with Live Server"**

âœ… Lâ€™interface est dÃ©jÃ  connectÃ©e au backend.  
Vous pouvez saisir un texte dans lâ€™interface : il sera envoyÃ© automatiquement au modÃ¨le, qui renverra une prÃ©diction (`Fake` ou `Real`) affichÃ©e instantanÃ©ment Ã  lâ€™utilisateur.

---

## ğŸ§  ModÃ¨le utilisÃ©

- **Architecture** : BERT (base uncased), modÃ¨le de rÃ©fÃ©rence pour le NLP

### ğŸ› ï¸ Techniques d'entraÃ®nement

- **Fine-tuning** : adaptation spÃ©cifique du modÃ¨le aux donnÃ©es de fake news  
- **QLoRA (4-bit)** : optimisation mÃ©moire pour lâ€™entraÃ®nement  
- **Quantization** : rÃ©duction de la taille du modÃ¨le sans perte significative de performance

### ğŸ§° Outils et bibliothÃ¨ques

- [Transformers](https://huggingface.co/docs/transformers/index) â€“ par HuggingFace  
- [Datasets](https://huggingface.co/docs/datasets/)  
- [bitsandbytes](https://github.com/TimDettmers/bitsandbytes) â€“ pour la quantization 4-bit  
- [PEFT](https://github.com/huggingface/peft) â€“ pour l'entraÃ®nement efficace avec LoRA  
- [PyTorch](https://pytorch.org/) â€“ framework de deep learning

---

## ğŸ‘¨â€ğŸ« Note Ã  lâ€™enseignant

**Remarque importante :**  
Les mÃ©triques globales du modÃ¨le (accuracy, f1-score,precision..) sont trÃ¨s Ã©levÃ©es et dÃ©montrent une bonne performance sur lâ€™ensemble des donnÃ©es.  
Cependant, lors de tests manuels via lâ€™UI, jâ€™ai constatÃ© que dans certains cas particuliers j'obtiens de faux resultat 

Cela peut Ãªtre dÃ» Ã  des limites du modÃ¨le BERT ou Ã  la complexitÃ© sÃ©mantique de certains exemples. Pour rÃ©soudre cela, je prÃ©vois dâ€™explorer :

- Une meilleure gestion du dÃ©sÃ©quilibre de classes
- Des techniques dâ€™augmentation de donnÃ©es ou dâ€™ensemblage
- Une piste dâ€™amÃ©lioration envisagÃ©e est lâ€™intÃ©gration dâ€™un module de fact-checking, permettant de vÃ©rifier la vÃ©racitÃ© des faits Ã©voquÃ©s dans les textes Ã  lâ€™aide de bases de connaissances externes ou dâ€™API spÃ©cialisÃ©es. Je me demande sâ€™il serait pertinent de lâ€™ajouter Ã  ce projet pour renforcer la robustesse du systÃ¨me.

Cette observation montre que, bien quâ€™efficace, le modÃ¨le nÃ©cessite encore des amÃ©liorations pour atteindre une robustesse optimale dans des cas rÃ©els.

Le backend et le frontend sont **complÃ¨tement intÃ©grÃ©s**.  
Lâ€™application fonctionne localement dÃ¨s lâ€™exÃ©cution de `uvicorn` et lâ€™ouverture de lâ€™interface.  
Toutes les Ã©tapes de traitement des donnÃ©es et dâ€™entraÃ®nement du modÃ¨le sont dÃ©taillÃ©es dans le notebook `main/Main.ipynb`.
